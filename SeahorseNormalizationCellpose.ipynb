{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dddf4346",
   "metadata": {},
   "source": [
    "# Seahorse Normalization Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360d3561",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Install dependencies if needed\n",
    "# !pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c035c79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.exposure import rescale_intensity\n",
    "from skimage.util import img_as_ubyte\n",
    "from cellpose import denoise, io, utils\n",
    "from imaris_ims_file_reader import ims\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ae68f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Input configuration\n",
    "FOLDER_PATH = ''         # path to images or zip\n",
    "UPLOAD_ZIP = False       # set True if providing a zip file\n",
    "NORMALIZE = True         # normalize Seahorse Excel file\n",
    "NUCLEAR_CHANNEL = 1      # index starting from 1\n",
    "CROP_TO_CENTER = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa9da2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- helper functions ---\n",
    "\n",
    "def convert_ims_to_tiff(src, dst, channel):\n",
    "    os.makedirs(dst, exist_ok=True)\n",
    "    for fname in os.listdir(src):\n",
    "        if fname.endswith('.ims'):\n",
    "            path = os.path.join(src, fname)\n",
    "            out = os.path.join(dst, f\"{os.path.splitext(fname)[0]}.tiff\")\n",
    "            reader = ims(path)\n",
    "            reader.save_multilayer_tiff_stack(location=out, time_point=0,\n",
    "                channel=channel-1, resolution_level=0)\n",
    "            reader.close()\n",
    "\n",
    "\n",
    "def histogram_bounds(images):\n",
    "    hists = []\n",
    "    for p in images:\n",
    "        img = imread(p)\n",
    "        if img.dtype == np.uint16:\n",
    "            h, _ = np.histogram(img, bins=65536, range=(0,65535))\n",
    "            hists.append(h)\n",
    "    hist = np.mean(hists, axis=0)\n",
    "    maxc = hist.max()\n",
    "    lower = np.argmax(hist >= maxc*0.30)\n",
    "    upper = len(hist) - 1 - np.argmax(hist[::-1] >= maxc*0.05)\n",
    "    return round(lower*1.05), min(round(upper*1.3), 65535)\n",
    "\n",
    "\n",
    "def crop_image(img, center=True):\n",
    "    img8 = (img/256).astype(np.uint8)\n",
    "    _, binary = cv2.threshold(img8,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    blurred = cv2.GaussianBlur(binary,(0,0),4)\n",
    "    _, binary = cv2.threshold(blurred,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    dilated = cv2.dilate(binary,np.ones((3,3),np.uint8),iterations=200)\n",
    "    n,_,stats,_ = cv2.connectedComponentsWithStats(dilated)\n",
    "    stats = [s for s in stats[1:] if s[cv2.CC_STAT_AREA] > 10_000_000]\n",
    "    if not stats:\n",
    "        return img\n",
    "    x,y,w,h = stats[0][:4]\n",
    "    crop = img[y:y+h, x:x+w]\n",
    "    if center:\n",
    "        cy,cx = crop.shape[0]//2, crop.shape[1]//2\n",
    "        mask = np.zeros_like(crop, dtype=np.uint8)\n",
    "        cv2.circle(mask, (cx,cy), 1500, 255, -1)\n",
    "        crop = cv2.bitwise_and(crop, crop, mask=mask)\n",
    "        yv,xv = np.where(mask)\n",
    "        crop = crop[yv.min():yv.max(), xv.min():xv.max()]\n",
    "    else:\n",
    "        crop = crop[100:-100,100:-100]\n",
    "    return crop\n",
    "\n",
    "\n",
    "def process_images(input_dir, nuclear_channel, crop_to_center):\n",
    "    tiff_dir = os.path.join(input_dir, 'tiff_conversion')\n",
    "    out_dir = os.path.join(input_dir, 'output')\n",
    "    crop_dir = os.path.join(out_dir, 'Cropped')\n",
    "    os.makedirs(crop_dir, exist_ok=True)\n",
    "    convert_ims_to_tiff(input_dir, tiff_dir, nuclear_channel)\n",
    "    images = [os.path.join(tiff_dir,f) for f in os.listdir(tiff_dir) if f.endswith('.tiff')]\n",
    "    low, high = histogram_bounds(images)\n",
    "    for p in images:\n",
    "        img = imread(p)\n",
    "        img = rescale_intensity(img, in_range=(low, high), out_range=(0,65535)).astype(np.uint16)\n",
    "        cropped = crop_image(img, crop_to_center)\n",
    "        imsave(os.path.join(crop_dir, os.path.basename(p)), cropped)\n",
    "    return crop_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae84534",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- segmentation and normalization ---\n",
    "\n",
    "def load_images(folder):\n",
    "    return [io.imread(os.path.join(folder,f)) for f in os.listdir(folder) if f.endswith('.tiff')]\n",
    "\n",
    "\n",
    "def segment_images(imgs, model_type, restore, channel, flow_th, cellprob_th):\n",
    "    model = denoise.CellposeDenoiseModel(gpu=True, model_type=model_type,\n",
    "                                         restore_type=f'{restore}_{model_type}')\n",
    "    masks = []\n",
    "    for img in imgs:\n",
    "        if len(img.shape)==3 and img.shape[0]==min(img.shape):\n",
    "            img = img.transpose(1,2,0)\n",
    "        m,_,_,_ = model.eval(img, channels=[channel-1,0],\n",
    "                             flow_threshold=flow_th,\n",
    "                             cellprob_threshold=cellprob_th)\n",
    "        masks.append(m.astype(np.uint16))\n",
    "    return masks\n",
    "\n",
    "\n",
    "def count_cells(masks, crop_to_center):\n",
    "    counts = []\n",
    "    for m in masks:\n",
    "        if crop_to_center:\n",
    "            h,w = m.shape\n",
    "            cy,cx = h//2,w//2\n",
    "            radius = int(0.98*min(h,w)/2)\n",
    "            rr,cc = utils.disk((cy,cx), radius, shape=m.shape)\n",
    "            roi = np.zeros_like(m, bool)\n",
    "            roi[rr,cc]=True\n",
    "            m = np.where(roi, m, 0)\n",
    "        labels = np.unique(m)\n",
    "        counts.append(len(labels[labels!=0]))\n",
    "    return counts\n",
    "\n",
    "\n",
    "def normalize_excel(excel_path, counts, wells, out_dir, column='OCR'):\n",
    "    rate = pd.read_excel(excel_path, sheet_name='Rate')\n",
    "    rate = rate[~rate['Group'].isin(['Blank','Background'])]\n",
    "    counts = pd.Series(counts, index=wells)\n",
    "    data = rate[['Time','Measurement','Well', column]].copy()\n",
    "    def norm(row):\n",
    "        if row['Well'] in counts:\n",
    "            row[column] /= counts[row['Well']]/1000\n",
    "        return row\n",
    "    data = data.apply(norm, axis=1)\n",
    "    out = os.path.join(out_dir, 'Processed_Seahorse_Data.xlsx')\n",
    "    data.pivot(index='Time', columns='Well', values=column).to_excel(out)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0338d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example execution\n",
    "if UPLOAD_ZIP and FOLDER_PATH.endswith('.zip'):\n",
    "    with zipfile.ZipFile(FOLDER_PATH,'r') as zf:\n",
    "        extract_dir = os.path.join(os.path.dirname(FOLDER_PATH),'Extracted_Files')\n",
    "        os.makedirs(extract_dir, exist_ok=True)\n",
    "        zf.extractall(extract_dir)\n",
    "        FOLDER_PATH = extract_dir\n",
    "\n",
    "cropped = process_images(FOLDER_PATH, NUCLEAR_CHANNEL, CROP_TO_CENTER)\n",
    "images = load_images(cropped)\n",
    "mask_list = segment_images(images, 'cyto3', 'oneclick', NUCLEAR_CHANNEL, 0.4, 0)\n",
    "counts = count_cells(mask_list, CROP_TO_CENTER)\n",
    "\n",
    "if NORMALIZE:\n",
    "    excel = [f for f in os.listdir(FOLDER_PATH) if f.endswith(('.xlsx','.xls'))]\n",
    "    if excel:\n",
    "        out = normalize_excel(os.path.join(FOLDER_PATH,excel[0]), counts,\n",
    "                               [os.path.splitext(os.path.basename(f))[0] for f in os.listdir(cropped)],\n",
    "                               cropped)\n",
    "        print('Data saved to', out)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
